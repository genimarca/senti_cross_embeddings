Begin: Loading training corpus
End: Loading training corpus
Begin: Loading evaluation corpus
End: Loading evaluation corpus
Begin: Loading embeddings
End: Loading embeddings
[[2006, 15, 4, 929, 398, 3999, 86, 9570, 19, 6, 432, 33, 4, 5660, 2400, 43918, 23, 4279, 428, 0, 1, 1], [363, 16, 3439, 10, 52264, 50, 167, 5260, 623, 6, 7, 1439, 17335, 586, 423, 5821, 23, 4, 1233, 1178, 6, 13519], [55946, 5431, 409, 10, 4, 926, 438, 11, 228, 0, 4, 593, 11, 46, 10850, 11, 105935, 9013, 107625, 1, 1, 1], [120, 219, 581, 10319, 156, 23, 4, 21935, 59, 3, 4, 1701, 65, 231, 18, 2024, 234, 14, 314, 290, 108, 32], [8, 8, 56, 51, 4189, 14, 117, 19, 9, 79, 19, 231, 11, 1, 1, 1, 1, 1, 1, 1, 1, 1]]
Begin: Training
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_1 (InputLayer)         (None, 22)                0         
_________________________________________________________________
embedding_1 (Embedding)      (None, 22, 100)           50000200  
_________________________________________________________________
bidirectional_1 (Bidirection (None, 22, 256)           234496    
_________________________________________________________________
dense_1 (Dense)              (None, 22, 64)            16448     
_________________________________________________________________
dropout_1 (Dropout)          (None, 22, 64)            0         
_________________________________________________________________
dense_2 (Dense)              (None, 22, 32)            2080      
_________________________________________________________________
dropout_2 (Dropout)          (None, 22, 32)            0         
_________________________________________________________________
flatten_1 (Flatten)          (None, 704)               0         
_________________________________________________________________
dense_3 (Dense)              (None, 2)                 1410      
=================================================================
Total params: 50,254,634
Trainable params: 254,434
Non-trainable params: 50,000,200
_________________________________________________________________
End: Training
Begin: Loading embeddings
End: Loading embeddings
[[8, 91473, 4430, 112, 7493, 0, 259, 31562, 27449, 4430, 7937, 32006, 114038, 259, 0, 9587, 4885, 225647, 1, 1, 1, 1], [8, 499, 4682, 31402, 778, 20090, 1734, 125008, 824, 0, 898, 0, 143281, 1, 1, 1, 1, 1, 1, 1, 1, 1], [8, 79319, 32006, 5038, 0, 312, 48510, 778, 49468, 15, 29, 44959, 77342, 1, 1, 1, 1, 1, 1, 1, 1, 1], [8, 0, 2993, 86163, 7, 79753, 8, 10213, 236262, 308271, 778, 312, 2993, 29, 32144, 7, 970, 23464, 1, 1, 1, 1], [8, 9837, 783, 104027, 15, 4947, 0, 824, 237436, 15, 29, 0, 20363, 37048, 98535, 1, 1, 1, 1, 1, 1, 1]]
Begin: Evaluation

  32/1409 [..............................] - ETA: 33s
 128/1409 [=>............................] - ETA: 8s 
 224/1409 [===>..........................] - ETA: 4s
 320/1409 [=====>........................] - ETA: 3s
 416/1409 [=======>......................] - ETA: 2s
 512/1409 [=========>....................] - ETA: 1s
 608/1409 [===========>..................] - ETA: 1s
 704/1409 [=============>................] - ETA: 1s
 800/1409 [================>.............] - ETA: 0s
 896/1409 [==================>...........] - ETA: 0s
 992/1409 [====================>.........] - ETA: 0s
1088/1409 [======================>.......] - ETA: 0s
1184/1409 [========================>.....] - ETA: 0s
1280/1409 [==========================>...] - ETA: 0s
1376/1409 [============================>.] - ETA: 0s
1409/1409 [==============================] - 2s 1ms/step
End: Test
Train_size:	 3957
Train_size NEGATIVE:	863
Train_size POSITIVE:	3094


Eva_size:	 1409
Eva_size NEGATIVE:	768
Eva_size POSITIVE:	642

	Pred_NEGATIVE	Pred_POSITIVE
R_NEGATIVE	5	762
R_POSITIVE	1	641

Prec. NEGATIVE: 0.8333333333333334
Prec. POSITIVE: 0.4568781183178902
Recall NEGATIVE: 0.00651890482398957
Recall POSITIVE: 0.9984423676012462
F1 NEGATIVE: 0.012936610608020701
F1 POSITIVE: 0.6268948655256723
Macro-Precision: 0.6451057258256118
Macro-Recall: 0.5024806362126178
Macro-F1: 0.3199157380668465
Accuracy: 0.45848119233498935

GoodBye

