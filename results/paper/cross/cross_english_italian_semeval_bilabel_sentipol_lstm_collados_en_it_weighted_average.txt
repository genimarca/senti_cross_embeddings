Begin: Loading training corpus
End: Loading training corpus
Begin: Loading evaluation corpus
End: Loading evaluation corpus
Begin: Loading embeddings
End: Loading embeddings
[[0, 242392, 96615, 216490, 406762, 81184, 298425, 50383, 0, 147498, 74639, 0, 129085, 496291, 140777, 0, 237301, 407335, 177314, 314353, 0, 242306], [0, 0, 367102, 266310, 0, 320909, 362436, 97825, 367102, 0, 49946, 396062, 0, 146508, 0, 422024, 0, 396062, 1, 1, 1, 1], [485313, 452492, 177117, 193552, 286207, 12213, 178587, 175732, 66370, 280689, 146508, 0, 0, 73234, 249884, 286667, 0, 51068, 320817, 320524, 147926, 231587], [117502, 0, 0, 0, 96399, 177314, 286667, 346168, 0, 96399, 102603, 396062, 872, 345965, 146508, 314259, 117502, 41296, 0, 242306, 0, 1], [0, 275907, 0, 146508, 160697, 410100, 286667, 371975, 41296, 385188, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]]
Begin: Training
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_1 (InputLayer)         (None, 22)                0         
_________________________________________________________________
embedding_1 (Embedding)      (None, 22, 100)           50000200  
_________________________________________________________________
bidirectional_1 (Bidirection (None, 22, 256)           234496    
_________________________________________________________________
dense_1 (Dense)              (None, 22, 64)            16448     
_________________________________________________________________
dropout_1 (Dropout)          (None, 22, 64)            0         
_________________________________________________________________
dense_2 (Dense)              (None, 22, 32)            2080      
_________________________________________________________________
dropout_2 (Dropout)          (None, 22, 32)            0         
_________________________________________________________________
flatten_1 (Flatten)          (None, 704)               0         
_________________________________________________________________
dense_3 (Dense)              (None, 2)                 1410      
=================================================================
Total params: 50,254,634
Trainable params: 254,434
Non-trainable params: 50,000,200
_________________________________________________________________
End: Training
Begin: Loading embeddings
End: Loading embeddings
[[120279, 101957, 280639, 140777, 155546, 255665, 0, 0, 0, 0, 0, 120279, 101957, 0, 242306, 0, 1, 1, 1, 1, 1, 1], [0, 0, 0, 0, 0, 0, 364037, 0, 0, 423749, 0, 0, 0, 343227, 280639, 280639, 0, 1, 1, 1, 1, 1], [120279, 101957, 280639, 140777, 155546, 255665, 0, 0, 0, 0, 0, 120279, 101957, 352313, 280639, 0, 1, 1, 1, 1, 1, 1], [280639, 0, 91542, 423749, 0, 0, 0, 0, 91542, 139871, 0, 0, 280557, 0, 33086, 0, 0, 242306, 415993, 438622, 320817, 77082], [280639, 330633, 0, 0, 194832, 264142, 0, 345039, 0, 257931, 0, 280639, 280639, 0, 1, 1, 1, 1, 1, 1, 1, 1]]
Begin: Evaluation

  32/1050 [..............................] - ETA: 5s
 128/1050 [==>...........................] - ETA: 1s
 224/1050 [=====>........................] - ETA: 0s
 320/1050 [========>.....................] - ETA: 0s
 416/1050 [==========>...................] - ETA: 0s
 512/1050 [=============>................] - ETA: 0s
 608/1050 [================>.............] - ETA: 0s
 704/1050 [===================>..........] - ETA: 0s
 800/1050 [=====================>........] - ETA: 0s
 896/1050 [========================>.....] - ETA: 0s
 992/1050 [===========================>..] - ETA: 0s
1050/1050 [==============================] - 1s 671us/step
End: Test
Train_size:	 3957
Train_size NEGATIVE:	863
Train_size POSITIVE:	3094


Eva_size:	 1050
Eva_size NEGATIVE:	734
Eva_size POSITIVE:	316

	Pred_NEGATIVE	Pred_POSITIVE
R_NEGATIVE	304	430
R_POSITIVE	79	237

Prec. NEGATIVE: 0.793733681462141
Prec. POSITIVE: 0.3553223388305847
Recall NEGATIVE: 0.4141689373297003
Recall POSITIVE: 0.75
F1 NEGATIVE: 0.5443151298119965
F1 POSITIVE: 0.4821973550356054
Macro-Precision: 0.5745280101463628
Macro-Recall: 0.5820844686648501
Macro-F1: 0.513256242423801
Accuracy: 0.5152380952380953

GoodBye

