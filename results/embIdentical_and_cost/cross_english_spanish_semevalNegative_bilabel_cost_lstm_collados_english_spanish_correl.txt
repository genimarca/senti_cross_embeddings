Begin: Loading training corpus
End: Loading training corpus
Begin: Loading evaluation corpus
End: Loading evaluation corpus
Begin: Loading embeddings
End: Loading embeddings
[[1408, 60, 41, 314, 7790, 13, 204, 6, 79, 6544, 193, 9, 10222, 11, 8, 0, 1, 1, 1, 1, 1, 1, 1], [8, 21, 22, 4, 308, 18, 3595, 164, 85, 5978, 140, 797, 872, 146, 6, 377, 23, 626, 11, 8, 0, 1, 1], [30, 24, 2506, 37, 4375, 2895, 28, 394, 221, 394, 962, 37, 7, 450, 64, 345, 0, 9, 68, 625, 4, 43, 14], [1346, 6, 239, 95, 4, 158, 29374, 12, 96068, 22, 2182, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [8, 34990, 674, 11, 708, 524, 732, 552, 1881, 36947, 64, 520, 311, 738, 15, 30, 19, 373, 31, 47, 6, 32, 41]]
Begin: Training
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_1 (InputLayer)         (None, 23)                0         
_________________________________________________________________
embedding_1 (Embedding)      (None, 23, 100)           50000200  
_________________________________________________________________
bidirectional_1 (Bidirection (None, 23, 256)           234496    
_________________________________________________________________
dense_1 (Dense)              (None, 23, 64)            16448     
_________________________________________________________________
dropout_1 (Dropout)          (None, 23, 64)            0         
_________________________________________________________________
dense_2 (Dense)              (None, 23, 32)            2080      
_________________________________________________________________
dropout_2 (Dropout)          (None, 23, 32)            0         
_________________________________________________________________
flatten_1 (Flatten)          (None, 736)               0         
_________________________________________________________________
dense_3 (Dense)              (None, 2)                 1474      
=================================================================
Total params: 50,254,698
Trainable params: 254,498
Non-trainable params: 50,000,200
_________________________________________________________________
End: Training
Begin: Loading embeddings
End: Loading embeddings
[[50304, 134, 1321, 503, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [8, 23464, 37048, 331385, 7, 312, 6415, 22424, 197, 49781, 15, 107267, 4430, 112, 7937, 2791, 3039, 8827, 2692, 23464, 146789, 15, 197], [8, 10213, 23758, 744, 10213, 4930, 778, 31299, 0, 10213, 19406, 1561, 191662, 15, 0, 898, 0, 5777, 14, 2692, 1, 1, 1], [8, 0, 66111, 11, 824, 303206, 778, 0, 1218, 389, 197, 0, 744, 151, 83230, 15, 10794, 84, 4299, 1, 1, 1, 1], [19162, 23653, 15, 28678, 24078, 503, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]]
Begin: Evaluation

   32/11426 [..............................] - ETA: 49s
  256/11426 [..............................] - ETA: 8s 
  480/11426 [>.............................] - ETA: 5s
  704/11426 [>.............................] - ETA: 4s
  928/11426 [=>............................] - ETA: 3s
 1152/11426 [==>...........................] - ETA: 3s
 1376/11426 [==>...........................] - ETA: 3s
 1600/11426 [===>..........................] - ETA: 3s
 1824/11426 [===>..........................] - ETA: 2s
 2048/11426 [====>.........................] - ETA: 2s
 2272/11426 [====>.........................] - ETA: 2s
 2496/11426 [=====>........................] - ETA: 2s
 2720/11426 [======>.......................] - ETA: 2s
 2944/11426 [======>.......................] - ETA: 2s
 3136/11426 [=======>......................] - ETA: 2s
 3360/11426 [=======>......................] - ETA: 2s
 3584/11426 [========>.....................] - ETA: 2s
 3808/11426 [========>.....................] - ETA: 2s
 4032/11426 [=========>....................] - ETA: 2s
 4224/11426 [==========>...................] - ETA: 1s
 4448/11426 [==========>...................] - ETA: 1s
 4672/11426 [===========>..................] - ETA: 1s
 4896/11426 [===========>..................] - ETA: 1s
 5120/11426 [============>.................] - ETA: 1s
 5344/11426 [=============>................] - ETA: 1s
 5536/11426 [=============>................] - ETA: 1s
 5760/11426 [==============>...............] - ETA: 1s
 5984/11426 [==============>...............] - ETA: 1s
 6208/11426 [===============>..............] - ETA: 1s
 6432/11426 [===============>..............] - ETA: 1s
 6656/11426 [================>.............] - ETA: 1s
 6880/11426 [=================>............] - ETA: 1s
 7104/11426 [=================>............] - ETA: 1s
 7360/11426 [==================>...........] - ETA: 1s
 7584/11426 [==================>...........] - ETA: 0s
 7808/11426 [===================>..........] - ETA: 0s
 8032/11426 [====================>.........] - ETA: 0s
 8256/11426 [====================>.........] - ETA: 0s
 8480/11426 [=====================>........] - ETA: 0s
 8736/11426 [=====================>........] - ETA: 0s
 8992/11426 [======================>.......] - ETA: 0s
 9248/11426 [=======================>......] - ETA: 0s
 9472/11426 [=======================>......] - ETA: 0s
 9728/11426 [========================>.....] - ETA: 0s
 9984/11426 [=========================>....] - ETA: 0s
10240/11426 [=========================>....] - ETA: 0s
10464/11426 [==========================>...] - ETA: 0s
10688/11426 [===========================>..] - ETA: 0s
10944/11426 [===========================>..] - ETA: 0s
11168/11426 [============================>.] - ETA: 0s
11392/11426 [============================>.] - ETA: 0s
11426/11426 [==============================] - 3s 249us/step
End: Test
Train_size:	 5872
Train_size NEGATIVE:	2778
Train_size POSITIVE:	3094


Eva_size:	 11426
Eva_size NEGATIVE:	5789
Eva_size POSITIVE:	5637

	Pred_NEGATIVE	Pred_POSITIVE
R_NEGATIVE	4258	1531
R_POSITIVE	516	5121

Prec. NEGATIVE: 0.8919145370758274
Prec. POSITIVE: 0.7698436560432953
Recall NEGATIVE: 0.7355329072378649
Recall POSITIVE: 0.9084619478445982
F1 NEGATIVE: 0.8062103569061819
F1 POSITIVE: 0.833428269183823
Macro-Precision: 0.8308790965595614
Macro-Recall: 0.8219974275412316
Macro-F1: 0.8198193130450024
Accuracy: 0.820847190617889

GoodBye

