Begin: Loading training corpus
End: Loading training corpus
Begin: Loading evaluation corpus
End: Loading evaluation corpus
Begin: Loading embeddings
End: Loading embeddings
[[276, 11, 30, 11319, 8, 134, 112, 6275, 21042, 23, 4, 3029, 11, 229, 4, 4897, 142, 13, 3020, 6, 510, 57], [54, 116, 7, 636, 103, 421, 6544, 2483, 132, 215, 9, 183, 6638, 231, 51, 26, 0, 1, 1, 1, 1, 1], [112, 3874, 16, 449, 108, 2290, 21273, 131, 172, 132, 378, 128, 57, 183, 3086, 3991, 282, 231, 1, 1, 1, 1], [293, 7, 74815, 11, 3872, 4104, 6, 60, 162, 7790, 17, 4375, 2895, 9, 257, 1635, 6, 15339, 24, 17, 7, 926], [3548, 397, 4386, 104, 804, 231, 33, 4088, 276, 35, 4, 145, 13, 39, 21, 435, 30, 133, 0, 1, 1, 1]]
Begin: Training
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_1 (InputLayer)         (None, 22)                0         
_________________________________________________________________
embedding_1 (Embedding)      (None, 22, 100)           50000200  
_________________________________________________________________
bidirectional_1 (Bidirection (None, 22, 256)           234496    
_________________________________________________________________
dense_1 (Dense)              (None, 22, 64)            16448     
_________________________________________________________________
dropout_1 (Dropout)          (None, 22, 64)            0         
_________________________________________________________________
dense_2 (Dense)              (None, 22, 32)            2080      
_________________________________________________________________
dropout_2 (Dropout)          (None, 22, 32)            0         
_________________________________________________________________
flatten_1 (Flatten)          (None, 704)               0         
_________________________________________________________________
dense_3 (Dense)              (None, 2)                 1410      
=================================================================
Total params: 50,254,634
Trainable params: 254,434
Non-trainable params: 50,000,200
_________________________________________________________________
End: Training
Begin: Loading embeddings
End: Loading embeddings
[[7070, 82, 8, 91, 192451, 428, 0, 11320, 0, 0, 0, 7070, 82, 0, 26, 0, 1, 1, 1, 1, 1, 1], [0, 102369, 0, 0, 5771, 0, 0, 0, 93969, 259, 0, 15, 0, 1218, 8, 8, 0, 1, 1, 1, 1, 1], [7070, 82, 8, 91, 192451, 428, 0, 11320, 0, 0, 0, 7070, 82, 8072, 8, 0, 1, 1, 1, 1, 1, 1], [8, 0, 23650, 259, 0, 0, 0, 119898, 23650, 33661, 0, 0, 5938, 9370, 17335, 7, 0, 26, 93536, 268155, 305, 18163], [8, 2955, 0, 0, 59315, 13, 0, 1695, 0, 4400, 0, 8, 8, 0, 1, 1, 1, 1, 1, 1, 1, 1]]
Begin: Evaluation

  32/1050 [..............................] - ETA: 12s
  96/1050 [=>............................] - ETA: 5s 
 160/1050 [===>..........................] - ETA: 3s
 256/1050 [======>.......................] - ETA: 2s
 320/1050 [========>.....................] - ETA: 1s
 384/1050 [=========>....................] - ETA: 1s
 480/1050 [============>.................] - ETA: 0s
 576/1050 [===============>..............] - ETA: 0s
 640/1050 [=================>............] - ETA: 0s
 704/1050 [===================>..........] - ETA: 0s
 768/1050 [====================>.........] - ETA: 0s
 832/1050 [======================>.......] - ETA: 0s
 896/1050 [========================>.....] - ETA: 0s
 960/1050 [==========================>...] - ETA: 0s
1024/1050 [============================>.] - ETA: 0s
1050/1050 [==============================] - 1s 1ms/step
End: Test
Train_size:	 3957
Train_size NEGATIVE:	863
Train_size POSITIVE:	3094


Eva_size:	 1050
Eva_size NEGATIVE:	734
Eva_size POSITIVE:	316

	Pred_NEGATIVE	Pred_POSITIVE
R_NEGATIVE	17	717
R_POSITIVE	6	310

Prec. NEGATIVE: 0.7391304347826086
Prec. POSITIVE: 0.3018500486854917
Recall NEGATIVE: 0.02316076294277929
Recall POSITIVE: 0.9810126582278481
F1 NEGATIVE: 0.04491413474240422
F1 POSITIVE: 0.4616530156366344
Macro-Precision: 0.5204902417340502
Macro-Recall: 0.5020867105853137
Macro-F1: 0.2532835751895193
Accuracy: 0.31142857142857144

GoodBye

