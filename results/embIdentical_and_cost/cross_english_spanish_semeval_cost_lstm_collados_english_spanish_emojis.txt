Begin: Loading training corpus
End: Loading training corpus
Begin: Loading evaluation corpus
End: Loading evaluation corpus
Begin: Loading embeddings
End: Loading embeddings
[[863, 1566, 134, 1321, 15, 814, 1171, 43761, 25, 2769, 22, 86, 31, 531, 425, 33, 3219, 69, 944, 356, 14, 0], [2573, 775, 11, 6138, 15, 54, 152, 1971, 28, 9, 2366, 22, 167, 1263, 366, 11, 0, 1, 1, 1, 1, 1], [8, 8, 10264, 53, 726, 10319, 58, 14, 254, 86, 26, 79, 19, 231, 11, 11, 1, 1, 1, 1, 1, 1], [90, 357, 91, 55946, 15, 0, 9, 0, 2159, 208, 185, 866, 91, 55946, 14515, 0, 17, 4, 2369, 43, 6, 26], [28505, 7, 1058, 14, 106, 19, 108, 432, 4, 926, 694, 12, 34752, 588, 276007, 174, 15894, 588, 89649, 1976, 3, 5816]]
Begin: Training
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_1 (InputLayer)         (None, 22)                0         
_________________________________________________________________
embedding_1 (Embedding)      (None, 22, 100)           50000200  
_________________________________________________________________
bidirectional_1 (Bidirection (None, 22, 256)           234496    
_________________________________________________________________
dense_1 (Dense)              (None, 22, 64)            16448     
_________________________________________________________________
dropout_1 (Dropout)          (None, 22, 64)            0         
_________________________________________________________________
dense_2 (Dense)              (None, 22, 32)            2080      
_________________________________________________________________
dropout_2 (Dropout)          (None, 22, 32)            0         
_________________________________________________________________
flatten_1 (Flatten)          (None, 704)               0         
_________________________________________________________________
dense_3 (Dense)              (None, 3)                 2115      
=================================================================
Total params: 50,255,339
Trainable params: 255,139
Non-trainable params: 50,000,200
_________________________________________________________________
End: Training
Begin: Loading embeddings
End: Loading embeddings
[[50304, 134, 1321, 503, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [8, 23464, 37048, 331385, 7, 312, 6415, 22424, 197, 49781, 15, 107267, 4430, 112, 7937, 2791, 3039, 8827, 2692, 23464, 146789, 15], [8, 10213, 23758, 744, 10213, 4930, 778, 31299, 0, 10213, 19406, 1561, 191662, 15, 0, 898, 0, 5777, 14, 2692, 1, 1], [8, 0, 66111, 11, 824, 303206, 778, 0, 1218, 389, 197, 0, 744, 151, 83230, 15, 10794, 84, 4299, 1, 1, 1], [19162, 23653, 15, 28678, 24078, 503, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]]
Begin: Evaluation

   32/11426 [..............................] - ETA: 34s
  288/11426 [..............................] - ETA: 5s 
  544/11426 [>.............................] - ETA: 4s
  800/11426 [=>............................] - ETA: 3s
 1056/11426 [=>............................] - ETA: 3s
 1312/11426 [==>...........................] - ETA: 2s
 1568/11426 [===>..........................] - ETA: 2s
 1792/11426 [===>..........................] - ETA: 2s
 2016/11426 [====>.........................] - ETA: 2s
 2240/11426 [====>.........................] - ETA: 2s
 2464/11426 [=====>........................] - ETA: 2s
 2656/11426 [=====>........................] - ETA: 2s
 2880/11426 [======>.......................] - ETA: 2s
 3072/11426 [=======>......................] - ETA: 2s
 3296/11426 [=======>......................] - ETA: 2s
 3520/11426 [========>.....................] - ETA: 2s
 3744/11426 [========>.....................] - ETA: 1s
 3968/11426 [=========>....................] - ETA: 1s
 4192/11426 [==========>...................] - ETA: 1s
 4416/11426 [==========>...................] - ETA: 1s
 4640/11426 [===========>..................] - ETA: 1s
 4864/11426 [===========>..................] - ETA: 1s
 5088/11426 [============>.................] - ETA: 1s
 5312/11426 [============>.................] - ETA: 1s
 5536/11426 [=============>................] - ETA: 1s
 5760/11426 [==============>...............] - ETA: 1s
 5984/11426 [==============>...............] - ETA: 1s
 6208/11426 [===============>..............] - ETA: 1s
 6432/11426 [===============>..............] - ETA: 1s
 6656/11426 [================>.............] - ETA: 1s
 6880/11426 [=================>............] - ETA: 1s
 7104/11426 [=================>............] - ETA: 1s
 7328/11426 [==================>...........] - ETA: 1s
 7552/11426 [==================>...........] - ETA: 0s
 7776/11426 [===================>..........] - ETA: 0s
 8000/11426 [====================>.........] - ETA: 0s
 8224/11426 [====================>.........] - ETA: 0s
 8448/11426 [=====================>........] - ETA: 0s
 8672/11426 [=====================>........] - ETA: 0s
 8896/11426 [======================>.......] - ETA: 0s
 9088/11426 [======================>.......] - ETA: 0s
 9312/11426 [=======================>......] - ETA: 0s
 9536/11426 [========================>.....] - ETA: 0s
 9760/11426 [========================>.....] - ETA: 0s
 9984/11426 [=========================>....] - ETA: 0s
10208/11426 [=========================>....] - ETA: 0s
10432/11426 [==========================>...] - ETA: 0s
10624/11426 [==========================>...] - ETA: 0s
10848/11426 [===========================>..] - ETA: 0s
11072/11426 [============================>.] - ETA: 0s
11296/11426 [============================>.] - ETA: 0s
11426/11426 [==============================] - 3s 251us/step
End: Test
Train_size:	 5999
Train_size NEGATIVE:	863
Train_size POSITIVE:	3094
Train_size NEUTRAL:	2043


Eva_size:	 11426
Eva_size NEGATIVE:	5789
Eva_size POSITIVE:	5637

	Pred_NEGATIVE	Pred_POSITIVE	Pred_None
R_NEGATIVE	1325	933	3531
R_POSITIVE	247	3029	2361
R_NEUTRAL	0	0	0

Prec. NEGATIVE: 0.8428753180661578
Prec. POSITIVE: 0.7645128722867238
Recall NEGATIVE: 0.22888236310243565
Recall POSITIVE: 0.5373425580982792
F1 NEGATIVE: 0.3600054340442875
F1 POSITIVE: 0.6311074070215648
Macro-Precision: 0.5357960634509605
Macro-Recall: 0.2554083070669049
Macro-F1: 0.33037094702195074
Accuracy: 0.3810607386661999

GoodBye

