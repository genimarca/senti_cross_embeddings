Begin: Loading training corpus
End: Loading training corpus
Begin: Loading evaluation corpus
End: Loading evaluation corpus
Begin: Loading embeddings
End: Loading embeddings
[[8, 8, 26781, 3683, 16338, 2873, 7, 1220, 2178, 20, 165, 82, 2303, 12, 39, 82, 0, 170, 36, 751, 198, 954], [13, 31, 1795, 91, 263, 834, 3437, 313, 4, 489, 4, 49909, 193, 968, 59, 0, 65, 263, 948, 917, 1423, 1229], [8, 8, 13, 108, 32, 486720, 9, 278, 77896, 32, 37, 17, 460, 4, 586, 5361, 7002, 505, 24, 226, 14, 0], [8, 13186, 27, 87, 47, 69, 6232, 17, 2770, 9919, 40, 19, 373, 853, 85, 69, 9478, 91, 0, 7052, 42470, 1], [12662, 133466, 26097, 265360, 20, 0, 14, 82, 106, 265360, 1943, 20, 165, 48173, 78, 21105, 15, 27, 373, 47, 6, 1902]]
Begin: Training
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_1 (InputLayer)         (None, 22)                0         
_________________________________________________________________
embedding_1 (Embedding)      (None, 22, 100)           50000200  
_________________________________________________________________
bidirectional_1 (Bidirection (None, 22, 256)           234496    
_________________________________________________________________
dense_1 (Dense)              (None, 22, 64)            16448     
_________________________________________________________________
dropout_1 (Dropout)          (None, 22, 64)            0         
_________________________________________________________________
dense_2 (Dense)              (None, 22, 32)            2080      
_________________________________________________________________
dropout_2 (Dropout)          (None, 22, 32)            0         
_________________________________________________________________
flatten_1 (Flatten)          (None, 704)               0         
_________________________________________________________________
dense_3 (Dense)              (None, 3)                 2115      
=================================================================
Total params: 50,255,339
Trainable params: 255,139
Non-trainable params: 50,000,200
_________________________________________________________________
End: Training
Begin: Loading embeddings
End: Loading embeddings
[[7070, 82, 8, 91, 192451, 428, 0, 11320, 0, 0, 0, 7070, 82, 0, 26, 0, 1, 1, 1, 1, 1, 1], [0, 102369, 0, 0, 5771, 0, 0, 0, 93969, 259, 0, 15, 0, 1218, 8, 8, 0, 1, 1, 1, 1, 1], [14, 8, 8, 0, 71644, 0, 1008, 339144, 0, 91912, 0, 13, 16405, 0, 1, 1, 1, 1, 1, 1, 1, 1], [7070, 82, 8, 91, 192451, 428, 0, 11320, 0, 0, 0, 7070, 82, 8072, 8, 0, 1, 1, 1, 1, 1, 1], [8, 0, 23650, 259, 0, 0, 0, 119898, 23650, 33661, 0, 0, 5938, 9370, 17335, 7, 0, 26, 93536, 268155, 305, 18163]]
Begin: Evaluation

  32/1305 [..............................] - ETA: 6s
 128/1305 [=>............................] - ETA: 1s
 256/1305 [====>.........................] - ETA: 1s
 384/1305 [=======>......................] - ETA: 0s
 512/1305 [==========>...................] - ETA: 0s
 640/1305 [=============>................] - ETA: 0s
 736/1305 [===============>..............] - ETA: 0s
 832/1305 [==================>...........] - ETA: 0s
 928/1305 [====================>.........] - ETA: 0s
1024/1305 [======================>.......] - ETA: 0s
1120/1305 [========================>.....] - ETA: 0s
1216/1305 [==========================>...] - ETA: 0s
1305/1305 [==============================] - 1s 636us/step
End: Test
Train_size:	 5999
Train_size NEGATIVE:	863
Train_size POSITIVE:	3094
Train_size NEUTRAL:	2043


Eva_size:	 1305
Eva_size NEGATIVE:	734
Eva_size POSITIVE:	316
Eva_size NEUTRAL:	255

	Pred_NEGATIVE	Pred_POSITIVE	Pred_NEUTRAL
R_NEGATIVE	5	501	228
R_POSITIVE	0	254	62
R_NEUTRAL	1	192	62

Prec. NEGATIVE: 0.8333333333333334
Prec. POSITIVE: 0.2682154171066526
Prec. NEUTRAL: 0.17613636363636365
Recall NEGATIVE: 0.006811989100817439
Recall POSITIVE: 0.8037974683544303
Recall NEUTRAL: 0.24313725490196078
F1 NEGATIVE: 0.013513513513513514
F1 POSITIVE: 0.4022169437846398
F1 NEUTRAL: 0.20428336079077428
Macro-Precision: 0.42589503802544987
Macro-Recall: 0.35124890411906956
Macro-F1: 0.20667127269630917
Accuracy: 0.24597701149425288

GoodBye

