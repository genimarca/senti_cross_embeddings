Begin: Loading training corpus
End: Loading training corpus
Begin: Loading evaluation corpus
End: Loading evaluation corpus
Begin: Loading embeddings
End: Loading embeddings
[[236, 7545, 128, 38, 4, 1740, 14, 13, 81, 30, 133, 109, 680, 313, 85, 18006, 42, 14, 1162, 63, 348, 33518], [8, 8, 106, 262, 416, 9325, 85, 329, 13, 373, 269, 1676, 4, 154, 623, 11, 262, 47, 48, 793, 3775, 14], [63, 166, 6, 1977, 17, 940, 23, 733, 13, 120, 249, 13, 93, 3776, 205, 21, 284, 1, 1, 1, 1, 1], [112, 158, 1726, 15, 31, 7, 12594, 38737, 2588, 0, 40, 5873, 7, 1956, 5582, 0, 1, 1, 1, 1, 1, 1], [12669, 22, 6638, 132, 12434, 40, 183, 77, 23, 1489, 223, 54, 6, 2104, 121, 2418, 159, 172, 132, 1, 1, 1]]
Begin: Training
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_1 (InputLayer)         (None, 22)                0         
_________________________________________________________________
embedding_1 (Embedding)      (None, 22, 100)           50000200  
_________________________________________________________________
bidirectional_1 (Bidirection (None, 22, 256)           234496    
_________________________________________________________________
dense_1 (Dense)              (None, 22, 64)            16448     
_________________________________________________________________
dropout_1 (Dropout)          (None, 22, 64)            0         
_________________________________________________________________
dense_2 (Dense)              (None, 22, 32)            2080      
_________________________________________________________________
dropout_2 (Dropout)          (None, 22, 32)            0         
_________________________________________________________________
flatten_1 (Flatten)          (None, 704)               0         
_________________________________________________________________
dense_3 (Dense)              (None, 3)                 2115      
=================================================================
Total params: 50,255,339
Trainable params: 255,139
Non-trainable params: 50,000,200
_________________________________________________________________
End: Training
Begin: Loading embeddings
End: Loading embeddings
[[7070, 82, 8, 91, 192451, 428, 0, 11320, 0, 0, 0, 7070, 82, 0, 26, 0, 1, 1, 1, 1, 1, 1], [0, 102369, 0, 0, 5771, 0, 0, 0, 93969, 259, 0, 15, 0, 1218, 8, 8, 0, 1, 1, 1, 1, 1], [14, 8, 8, 0, 71644, 0, 1008, 339144, 0, 91912, 0, 13, 16405, 0, 1, 1, 1, 1, 1, 1, 1, 1], [7070, 82, 8, 91, 192451, 428, 0, 11320, 0, 0, 0, 7070, 82, 8072, 8, 0, 1, 1, 1, 1, 1, 1], [8, 0, 23650, 259, 0, 0, 0, 119898, 23650, 33661, 0, 0, 5938, 9370, 17335, 7, 0, 26, 93536, 268155, 305, 18163]]
Begin: Evaluation

  32/1305 [..............................] - ETA: 37s
 128/1305 [=>............................] - ETA: 9s 
 224/1305 [====>.........................] - ETA: 4s
 320/1305 [======>.......................] - ETA: 3s
 416/1305 [========>.....................] - ETA: 2s
 544/1305 [===========>..................] - ETA: 1s
 640/1305 [=============>................] - ETA: 1s
 736/1305 [===============>..............] - ETA: 1s
 832/1305 [==================>...........] - ETA: 0s
 960/1305 [=====================>........] - ETA: 0s
1056/1305 [=======================>......] - ETA: 0s
1152/1305 [=========================>....] - ETA: 0s
1280/1305 [============================>.] - ETA: 0s
1305/1305 [==============================] - 2s 1ms/step
End: Test
Train_size:	 5999
Train_size NEGATIVE:	863
Train_size POSITIVE:	3094
Train_size NEUTRAL:	2043


Eva_size:	 1305
Eva_size NEGATIVE:	734
Eva_size POSITIVE:	316
Eva_size NEUTRAL:	255

	Pred_NEGATIVE	Pred_POSITIVE	Pred_NEUTRAL
R_NEGATIVE	7	333	394
R_POSITIVE	0	217	99
R_NEUTRAL	5	143	107

Prec. NEGATIVE: 0.5833333333333334
Prec. POSITIVE: 0.31313131313131315
Prec. NEUTRAL: 0.17833333333333334
Recall NEGATIVE: 0.009536784741144414
Recall POSITIVE: 0.6867088607594937
Recall NEUTRAL: 0.4196078431372549
F1 NEGATIVE: 0.018766756032171584
F1 POSITIVE: 0.43012884043607535
F1 NEUTRAL: 0.25029239766081873
Macro-Precision: 0.3582659932659933
Macro-Recall: 0.3719511628792977
Macro-F1: 0.2330626647096886
Accuracy: 0.25363984674329504

GoodBye

