Begin: Loading training corpus
End: Loading training corpus
Begin: Loading evaluation corpus
End: Loading evaluation corpus
Begin: Loading embeddings
End: Loading embeddings
[[0, 408, 40, 73755, 0, 413807, 2520, 0, 1, 1, 1, 1], [48, 82, 2670, 423, 4, 33, 9100, 61, 484, 1, 1, 1], [8134, 16, 35, 3290, 130, 31, 16, 27, 27, 32817, 484, 6], [277, 195, 121, 18, 1443, 478, 39, 70987, 484, 1, 1, 1], [6, 5470, 10, 623, 3, 11, 176, 90, 691, 128680, 43, 3544]]
Begin: Training
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_1 (InputLayer)         (None, 12)                0         
_________________________________________________________________
embedding_1 (Embedding)      (None, 12, 100)           50000200  
_________________________________________________________________
bidirectional_1 (Bidirection (None, 12, 256)           234496    
_________________________________________________________________
dense_1 (Dense)              (None, 12, 64)            16448     
_________________________________________________________________
dropout_1 (Dropout)          (None, 12, 64)            0         
_________________________________________________________________
dense_2 (Dense)              (None, 12, 32)            2080      
_________________________________________________________________
dropout_2 (Dropout)          (None, 12, 32)            0         
_________________________________________________________________
flatten_1 (Flatten)          (None, 384)               0         
_________________________________________________________________
dense_3 (Dense)              (None, 2)                 770       
=================================================================
Total params: 50,253,994
Trainable params: 253,794
Non-trainable params: 50,000,200
_________________________________________________________________
End: Training
[[111681, 330, 4773, 484, 1, 1, 1, 1, 1, 1, 1, 1], [6, 62, 60, 11178, 12, 39, 47588, 129, 29, 116, 4, 189], [6, 31, 230, 8, 31, 143598, 3, 1449, 21932, 31, 1028, 23], [6, 385309, 714, 10, 15, 10678, 3, 0, 244, 65, 29, 155674], [172, 666, 4, 260, 320, 484, 0, 1, 1, 1, 1, 1]]
Begin: Evaluation

   32/11426 [..............................] - ETA: 1:03
  224/11426 [..............................] - ETA: 11s 
  416/11426 [>.............................] - ETA: 7s 
  608/11426 [>.............................] - ETA: 6s
  800/11426 [=>............................] - ETA: 5s
  992/11426 [=>............................] - ETA: 4s
 1184/11426 [==>...........................] - ETA: 4s
 1376/11426 [==>...........................] - ETA: 4s
 1568/11426 [===>..........................] - ETA: 4s
 1760/11426 [===>..........................] - ETA: 3s
 1952/11426 [====>.........................] - ETA: 3s
 2112/11426 [====>.........................] - ETA: 3s
 2272/11426 [====>.........................] - ETA: 3s
 2464/11426 [=====>........................] - ETA: 3s
 2656/11426 [=====>........................] - ETA: 3s
 2848/11426 [======>.......................] - ETA: 3s
 3040/11426 [======>.......................] - ETA: 3s
 3232/11426 [=======>......................] - ETA: 2s
 3424/11426 [=======>......................] - ETA: 2s
 3616/11426 [========>.....................] - ETA: 2s
 3808/11426 [========>.....................] - ETA: 2s
 3936/11426 [=========>....................] - ETA: 2s
 4128/11426 [=========>....................] - ETA: 2s
 4320/11426 [==========>...................] - ETA: 2s
 4512/11426 [==========>...................] - ETA: 2s
 4672/11426 [===========>..................] - ETA: 2s
 4832/11426 [===========>..................] - ETA: 2s
 4992/11426 [============>.................] - ETA: 2s
 5184/11426 [============>.................] - ETA: 2s
 5376/11426 [=============>................] - ETA: 2s
 5568/11426 [=============>................] - ETA: 1s
 5760/11426 [==============>...............] - ETA: 1s
 5952/11426 [==============>...............] - ETA: 1s
 6112/11426 [===============>..............] - ETA: 1s
 6304/11426 [===============>..............] - ETA: 1s
 6496/11426 [================>.............] - ETA: 1s
 6688/11426 [================>.............] - ETA: 1s
 6880/11426 [=================>............] - ETA: 1s
 7072/11426 [=================>............] - ETA: 1s
 7264/11426 [==================>...........] - ETA: 1s
 7456/11426 [==================>...........] - ETA: 1s
 7648/11426 [===================>..........] - ETA: 1s
 7840/11426 [===================>..........] - ETA: 1s
 8032/11426 [====================>.........] - ETA: 1s
 8224/11426 [====================>.........] - ETA: 1s
 8416/11426 [=====================>........] - ETA: 0s
 8576/11426 [=====================>........] - ETA: 0s
 8768/11426 [======================>.......] - ETA: 0s
 8960/11426 [======================>.......] - ETA: 0s
 9152/11426 [=======================>......] - ETA: 0s
 9344/11426 [=======================>......] - ETA: 0s
 9536/11426 [========================>.....] - ETA: 0s
 9728/11426 [========================>.....] - ETA: 0s
 9920/11426 [=========================>....] - ETA: 0s
10112/11426 [=========================>....] - ETA: 0s
10304/11426 [==========================>...] - ETA: 0s
10496/11426 [==========================>...] - ETA: 0s
10688/11426 [===========================>..] - ETA: 0s
10880/11426 [===========================>..] - ETA: 0s
11072/11426 [============================>.] - ETA: 0s
11264/11426 [============================>.] - ETA: 0s
11426/11426 [==============================] - 4s 322us/step
End: Test
Train_size:	 23196
Train_size NEGATIVE:	11525
Train_size POSITIVE:	11671


Eva_size:	 11426
Eva_size NEGATIVE:	5789
Eva_size POSITIVE:	5637

	Pred_NEGATIVE	Pred_POSITIVE
R_NEGATIVE	5081	708
R_POSITIVE	672	4965

Prec. NEGATIVE: 0.8831913784112637
Prec. POSITIVE: 0.8751983077736647
Recall NEGATIVE: 0.8776990844705476
Recall POSITIVE: 0.8807876530069185
F1 NEGATIVE: 0.880436666089066
F1 POSITIVE: 0.8779840848806366
Macro-Precision: 0.8791948430924642
Macro-Recall: 0.8792433687387331
Macro-F1: 0.8792103754848513
Accuracy: 0.8792228251356555

GoodBye

