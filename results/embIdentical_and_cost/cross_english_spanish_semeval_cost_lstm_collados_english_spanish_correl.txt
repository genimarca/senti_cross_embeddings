Begin: Loading training corpus
End: Loading training corpus
Begin: Loading evaluation corpus
End: Loading evaluation corpus
Begin: Loading embeddings
End: Loading embeddings
[[12662, 133466, 26097, 265360, 20, 0, 14, 82, 106, 265360, 1943, 20, 165, 48173, 78, 21105, 15, 27, 373, 47, 6, 1902], [112, 949, 12, 163379, 10, 4, 944, 89649, 0, 14, 59, 1146, 4328, 7728, 65, 0, 1, 1, 1, 1, 1, 1], [168, 36, 137, 48, 88, 0, 267, 435, 40, 69306, 95, 1138, 170, 36, 1821, 23359, 23, 264, 224, 2031, 242, 13], [293, 7, 56, 28, 10, 34701, 11, 12172, 15, 1746, 2183, 463, 15, 925, 9, 330, 5945, 503, 34701, 12082, 357, 28], [16, 1896, 8, 1489, 179, 20, 122410, 176, 992, 244, 23, 7, 1873, 10, 4, 83, 14, 63, 71035, 263, 17, 18373]]
Begin: Training
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_1 (InputLayer)         (None, 22)                0         
_________________________________________________________________
embedding_1 (Embedding)      (None, 22, 100)           50000200  
_________________________________________________________________
bidirectional_1 (Bidirection (None, 22, 256)           234496    
_________________________________________________________________
dense_1 (Dense)              (None, 22, 64)            16448     
_________________________________________________________________
dropout_1 (Dropout)          (None, 22, 64)            0         
_________________________________________________________________
dense_2 (Dense)              (None, 22, 32)            2080      
_________________________________________________________________
dropout_2 (Dropout)          (None, 22, 32)            0         
_________________________________________________________________
flatten_1 (Flatten)          (None, 704)               0         
_________________________________________________________________
dense_3 (Dense)              (None, 3)                 2115      
=================================================================
Total params: 50,255,339
Trainable params: 255,139
Non-trainable params: 50,000,200
_________________________________________________________________
End: Training
Begin: Loading embeddings
End: Loading embeddings
[[50304, 134, 1321, 503, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [8, 23464, 37048, 331385, 7, 312, 6415, 22424, 197, 49781, 15, 107267, 4430, 112, 7937, 2791, 3039, 8827, 2692, 23464, 146789, 15], [8, 10213, 23758, 744, 10213, 4930, 778, 31299, 0, 10213, 19406, 1561, 191662, 15, 0, 898, 0, 5777, 14, 2692, 1, 1], [8, 0, 66111, 11, 824, 303206, 778, 0, 1218, 389, 197, 0, 744, 151, 83230, 15, 10794, 84, 4299, 1, 1, 1], [19162, 23653, 15, 28678, 24078, 503, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]]
Begin: Evaluation

   32/11426 [..............................] - ETA: 40s
  256/11426 [..............................] - ETA: 7s 
  480/11426 [>.............................] - ETA: 5s
  704/11426 [>.............................] - ETA: 4s
  928/11426 [=>............................] - ETA: 3s
 1152/11426 [==>...........................] - ETA: 3s
 1376/11426 [==>...........................] - ETA: 3s
 1632/11426 [===>..........................] - ETA: 2s
 1856/11426 [===>..........................] - ETA: 2s
 2080/11426 [====>.........................] - ETA: 2s
 2304/11426 [=====>........................] - ETA: 2s
 2496/11426 [=====>........................] - ETA: 2s
 2688/11426 [======>.......................] - ETA: 2s
 2880/11426 [======>.......................] - ETA: 2s
 3104/11426 [=======>......................] - ETA: 2s
 3328/11426 [=======>......................] - ETA: 2s
 3584/11426 [========>.....................] - ETA: 2s
 3840/11426 [=========>....................] - ETA: 2s
 4064/11426 [=========>....................] - ETA: 1s
 4320/11426 [==========>...................] - ETA: 1s
 4544/11426 [==========>...................] - ETA: 1s
 4768/11426 [===========>..................] - ETA: 1s
 4992/11426 [============>.................] - ETA: 1s
 5248/11426 [============>.................] - ETA: 1s
 5504/11426 [=============>................] - ETA: 1s
 5760/11426 [==============>...............] - ETA: 1s
 6016/11426 [==============>...............] - ETA: 1s
 6272/11426 [===============>..............] - ETA: 1s
 6528/11426 [================>.............] - ETA: 1s
 6784/11426 [================>.............] - ETA: 1s
 7040/11426 [=================>............] - ETA: 1s
 7264/11426 [==================>...........] - ETA: 1s
 7488/11426 [==================>...........] - ETA: 0s
 7712/11426 [===================>..........] - ETA: 0s
 7936/11426 [===================>..........] - ETA: 0s
 8160/11426 [====================>.........] - ETA: 0s
 8384/11426 [=====================>........] - ETA: 0s
 8608/11426 [=====================>........] - ETA: 0s
 8864/11426 [======================>.......] - ETA: 0s
 9120/11426 [======================>.......] - ETA: 0s
 9344/11426 [=======================>......] - ETA: 0s
 9600/11426 [========================>.....] - ETA: 0s
 9824/11426 [========================>.....] - ETA: 0s
10048/11426 [=========================>....] - ETA: 0s
10272/11426 [=========================>....] - ETA: 0s
10496/11426 [==========================>...] - ETA: 0s
10720/11426 [===========================>..] - ETA: 0s
10976/11426 [===========================>..] - ETA: 0s
11200/11426 [============================>.] - ETA: 0s
11424/11426 [============================>.] - ETA: 0s
11426/11426 [==============================] - 3s 243us/step
End: Test
Train_size:	 5999
Train_size NEGATIVE:	863
Train_size POSITIVE:	3094
Train_size NEUTRAL:	2043


Eva_size:	 11426
Eva_size NEGATIVE:	5789
Eva_size POSITIVE:	5637

	Pred_NEGATIVE	Pred_POSITIVE	Pred_None
R_NEGATIVE	506	1470	3813
R_POSITIVE	8	4321	1308
R_NEUTRAL	0	0	0

Prec. NEGATIVE: 0.9844357976653697
Prec. POSITIVE: 0.7461578311172509
Recall NEGATIVE: 0.08740715149421316
Recall POSITIVE: 0.7665424871385489
F1 NEGATIVE: 0.16055846422338566
F1 POSITIVE: 0.756212810640532
Macro-Precision: 0.5768645429275402
Macro-Recall: 0.284649879544254
Macro-F1: 0.30559042495463923
Accuracy: 0.4224575529494136

GoodBye

