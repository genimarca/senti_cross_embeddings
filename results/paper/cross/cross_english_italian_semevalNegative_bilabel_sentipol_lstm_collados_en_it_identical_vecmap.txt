Begin: Loading training corpus
End: Loading training corpus
Begin: Loading evaluation corpus
End: Loading evaluation corpus
Begin: Loading embeddings
End: Loading embeddings
[[16078, 91, 4, 263, 7523, 263, 12, 2770, 751, 91, 7, 40129, 12, 2006, 0, 5932, 19, 373, 47, 903, 174, 171, 26], [47, 7, 55, 626, 38, 12, 19, 48, 339, 28, 12104, 13848, 78, 5325, 2572, 1280, 0, 1, 1, 1, 1, 1, 1], [926, 51, 4481, 134, 116, 23, 24, 121, 435, 276, 435, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [8, 1205, 79, 29, 2692, 63, 128, 6, 16864, 999, 42, 17, 4, 124, 14, 3338, 8059, 85, 189, 11, 1, 1, 1], [204, 6, 1167, 95, 4375, 6044, 1648, 84, 115, 95, 304303, 2391, 19788, 84, 352, 29, 18, 412, 2391, 251, 23, 50124, 0]]
Begin: Training
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_1 (InputLayer)         (None, 23)                0         
_________________________________________________________________
embedding_1 (Embedding)      (None, 23, 100)           50000200  
_________________________________________________________________
bidirectional_1 (Bidirection (None, 23, 256)           234496    
_________________________________________________________________
dense_1 (Dense)              (None, 23, 64)            16448     
_________________________________________________________________
dropout_1 (Dropout)          (None, 23, 64)            0         
_________________________________________________________________
dense_2 (Dense)              (None, 23, 32)            2080      
_________________________________________________________________
dropout_2 (Dropout)          (None, 23, 32)            0         
_________________________________________________________________
flatten_1 (Flatten)          (None, 736)               0         
_________________________________________________________________
dense_3 (Dense)              (None, 2)                 1474      
=================================================================
Total params: 50,254,698
Trainable params: 254,498
Non-trainable params: 50,000,200
_________________________________________________________________
End: Training
Begin: Loading embeddings
End: Loading embeddings
[[7070, 82, 8, 91, 192451, 428, 0, 11320, 0, 0, 0, 7070, 82, 0, 26, 0, 1, 1, 1, 1, 1, 1, 1], [0, 102369, 0, 0, 5771, 0, 0, 0, 93969, 259, 0, 15, 0, 1218, 8, 8, 0, 1, 1, 1, 1, 1, 1], [7070, 82, 8, 91, 192451, 428, 0, 11320, 0, 0, 0, 7070, 82, 8072, 8, 0, 1, 1, 1, 1, 1, 1, 1], [8, 0, 23650, 259, 0, 0, 0, 119898, 23650, 33661, 0, 0, 5938, 9370, 17335, 7, 0, 26, 93536, 268155, 305, 18163, 5938], [8, 2955, 0, 0, 59315, 13, 0, 1695, 0, 4400, 0, 8, 8, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1]]
Begin: Evaluation

  32/1050 [..............................] - ETA: 12s
 128/1050 [==>...........................] - ETA: 3s 
 224/1050 [=====>........................] - ETA: 1s
 288/1050 [=======>......................] - ETA: 1s
 352/1050 [=========>....................] - ETA: 1s
 416/1050 [==========>...................] - ETA: 1s
 480/1050 [============>.................] - ETA: 0s
 544/1050 [==============>...............] - ETA: 0s
 608/1050 [================>.............] - ETA: 0s
 672/1050 [==================>...........] - ETA: 0s
 736/1050 [====================>.........] - ETA: 0s
 800/1050 [=====================>........] - ETA: 0s
 864/1050 [=======================>......] - ETA: 0s
 928/1050 [=========================>....] - ETA: 0s
 992/1050 [===========================>..] - ETA: 0s
1050/1050 [==============================] - 1s 1ms/step
End: Test
Train_size:	 5872
Train_size NEGATIVE:	2778
Train_size POSITIVE:	3094


Eva_size:	 1050
Eva_size NEGATIVE:	734
Eva_size POSITIVE:	316

	Pred_NEGATIVE	Pred_POSITIVE
R_NEGATIVE	359	375
R_POSITIVE	98	218

Prec. NEGATIVE: 0.7855579868708972
Prec. POSITIVE: 0.3676222596964587
Recall NEGATIVE: 0.4891008174386921
Recall POSITIVE: 0.689873417721519
F1 NEGATIVE: 0.6028547439126785
F1 POSITIVE: 0.4796479647964797
Macro-Precision: 0.5765901232836779
Macro-Recall: 0.5894871175801055
Macro-F1: 0.541251354354579
Accuracy: 0.5495238095238095

GoodBye

