Begin: Loading training corpus
End: Loading training corpus
Begin: Loading evaluation corpus
End: Loading evaluation corpus
Begin: Loading embeddings
End: Loading embeddings
[[265369, 125, 95, 40, 987, 12853, 84, 2382, 10798, 78, 78771, 586, 1427, 4109, 758, 5460, 14, 0, 10795, 0, 1, 1], [8, 8, 8, 82, 62452, 999, 48388, 7, 2711, 95, 4, 18685, 12, 7, 1701, 23209, 368, 82, 15, 760, 179, 7552], [2269, 1090, 33, 6019, 14, 11170, 9, 9, 4091, 4723, 13620, 11077, 23, 4, 4324, 12, 985, 10, 1147, 9, 3495, 91], [30, 8, 22, 9660, 2455, 48623, 17, 4, 0, 5055, 43, 15, 50, 6014, 7535, 84, 23368, 14, 1, 1, 1, 1], [13, 31, 3706, 63, 581, 5978, 140, 797, 231, 14, 1416, 637, 15, 257, 4533, 3604, 7, 103, 17, 21, 11, 1]]
Begin: Training
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_1 (InputLayer)         (None, 22)                0         
_________________________________________________________________
embedding_1 (Embedding)      (None, 22, 100)           50000200  
_________________________________________________________________
bidirectional_1 (Bidirection (None, 22, 256)           234496    
_________________________________________________________________
dense_1 (Dense)              (None, 22, 64)            16448     
_________________________________________________________________
dropout_1 (Dropout)          (None, 22, 64)            0         
_________________________________________________________________
dense_2 (Dense)              (None, 22, 32)            2080      
_________________________________________________________________
dropout_2 (Dropout)          (None, 22, 32)            0         
_________________________________________________________________
flatten_1 (Flatten)          (None, 704)               0         
_________________________________________________________________
dense_3 (Dense)              (None, 2)                 1410      
=================================================================
Total params: 50,254,634
Trainable params: 254,434
Non-trainable params: 50,000,200
_________________________________________________________________
End: Training
Begin: Loading embeddings
End: Loading embeddings
[[7070, 82, 8, 91, 192451, 428, 0, 11320, 0, 0, 0, 7070, 82, 0, 26, 0, 1, 1, 1, 1, 1, 1], [0, 102369, 0, 0, 5771, 0, 0, 0, 93969, 259, 0, 15, 0, 1218, 8, 8, 0, 1, 1, 1, 1, 1], [7070, 82, 8, 91, 192451, 428, 0, 11320, 0, 0, 0, 7070, 82, 8072, 8, 0, 1, 1, 1, 1, 1, 1], [8, 0, 23650, 259, 0, 0, 0, 119898, 23650, 33661, 0, 0, 5938, 9370, 17335, 7, 0, 26, 93536, 268155, 305, 18163], [8, 2955, 0, 0, 59315, 13, 0, 1695, 0, 4400, 0, 8, 8, 0, 1, 1, 1, 1, 1, 1, 1, 1]]
Begin: Evaluation

  32/1050 [..............................] - ETA: 11s
 128/1050 [==>...........................] - ETA: 2s 
 224/1050 [=====>........................] - ETA: 1s
 320/1050 [========>.....................] - ETA: 1s
 416/1050 [==========>...................] - ETA: 0s
 512/1050 [=============>................] - ETA: 0s
 608/1050 [================>.............] - ETA: 0s
 704/1050 [===================>..........] - ETA: 0s
 800/1050 [=====================>........] - ETA: 0s
 896/1050 [========================>.....] - ETA: 0s
 992/1050 [===========================>..] - ETA: 0s
1050/1050 [==============================] - 1s 903us/step
End: Test
Train_size:	 3957
Train_size NEGATIVE:	863
Train_size POSITIVE:	3094


Eva_size:	 1050
Eva_size NEGATIVE:	734
Eva_size POSITIVE:	316

	Pred_NEGATIVE	Pred_POSITIVE
R_NEGATIVE	104	630
R_POSITIVE	42	274

Prec. NEGATIVE: 0.7123287671232876
Prec. POSITIVE: 0.3030973451327434
Recall NEGATIVE: 0.14168937329700274
Recall POSITIVE: 0.8670886075949367
F1 NEGATIVE: 0.2363636363636364
F1 POSITIVE: 0.4491803278688525
Macro-Precision: 0.5077130561280155
Macro-Recall: 0.5043889904459697
Macro-F1: 0.34277198211624443
Accuracy: 0.36

GoodBye

